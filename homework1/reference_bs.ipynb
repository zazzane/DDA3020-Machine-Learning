{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instance_id  sepal length  sepal width  petal length  petal width  \\\n",
       "0            1           5.1          3.5           1.4          0.2   \n",
       "1            2           4.9          3.0           1.4          0.2   \n",
       "2            3           4.7          3.2           1.3          0.2   \n",
       "3            4           4.6          3.1           1.5          0.2   \n",
       "4            5           5.0          3.6           1.4          0.2   \n",
       "\n",
       "         class  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded file to check its content\n",
    "file_path = 'Classification iris.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Iris-setosa        35\n",
       "Iris-versicolor    35\n",
       "Iris-virginica     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (70%-30% split) while maintaining the original order per class\n",
    "\n",
    "# First, let's count the number of instances per class\n",
    "class_counts = data['class'].value_counts()\n",
    "\n",
    "# Calculate 70% of instances per class\n",
    "train_percentage = 0.7\n",
    "train_counts = (class_counts * train_percentage).astype(int)\n",
    "\n",
    "# Create empty lists for training and test data\n",
    "train_set = pd.DataFrame()\n",
    "test_set = pd.DataFrame()\n",
    "\n",
    "# Perform the split per class\n",
    "for iris_class in class_counts.index:\n",
    "    class_data = data[data['class'] == iris_class]\n",
    "    train_data = class_data.iloc[:train_counts[iris_class]]\n",
    "    test_data = class_data.iloc[train_counts[iris_class]:]\n",
    "    \n",
    "    train_set = pd.concat([train_set, train_data], ignore_index=True)\n",
    "    test_set = pd.concat([test_set, test_data], ignore_index=True)\n",
    "\n",
    "# Output the instance IDs of the split sets\n",
    "train_instance_ids = train_set['instance_id'].tolist()\n",
    "test_instance_ids = test_set['instance_id'].tolist()\n",
    "\n",
    "print(len(train_instance_ids))\n",
    " \n",
    "print(len(test_instance_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01904761904761909,\n",
       " 0.0,\n",
       " array([ 0.00945021,  0.53765319, -0.82682922, -0.38216595]),\n",
       " np.float64(0.7740991775898646),\n",
       " array([ 23,  24,  42,  55,  57,  62,  68,  76,  96,  97,  99, 103],\n",
       "       dtype=int32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare the feature set (X) and the labels (y)\n",
    "X_train = train_set[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
    "y_train = train_set['class']\n",
    "X_test = test_set[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
    "y_test = test_set['class']\n",
    "\n",
    "# Convert the class labels to numeric format using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Train the SVM model with a linear kernel and a large C value to simulate a hard margin\n",
    "svm_model = svm.SVC(kernel='linear', C=1e5)\n",
    "svm_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "y_train_pred = svm_model.predict(X_train)\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate training and testing errors (misclassification rates)\n",
    "train_error = 1 - accuracy_score(y_train_encoded, y_train_pred)\n",
    "test_error = 1 - accuracy_score(y_test_encoded, y_test_pred)\n",
    "\n",
    "# Get the weight vector, bias, and support vector indices\n",
    "w = svm_model.coef_[0]\n",
    "b = svm_model.intercept_[0]\n",
    "support_vectors = svm_model.support_\n",
    "\n",
    "# Organize and display results\n",
    "train_error, test_error, w, b, support_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.2 Calculation using Standard SVM Model:\n",
      "total training error: 0.019, total testing error: 0.000\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "w: [0.009733, 0.537779, -0.827351, -0.382043], b: 0.7735,\n",
      "support vector indices: [42, 23, 24]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.248, testing error: 0.289,\n",
      "w: [1.848600, -4.502374, -1.104339, 0.321285], b: 5.6773,\n",
      "support vector indices: [1, 2, 8, 9, 13, 25, 27, 34, 71, 72, 73, 77, 78, 80, 81, 86, 88, 89, 90, 91, 92, 93, 96, 99, 100, 102, 103, 104, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 55, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.019, testing error: 0.000,\n",
      "w: [-3.646504, -5.176364, 7.428526, 11.002416], b: -17.5704,\n",
      "support vector indices: [55, 57, 62, 68, 96, 97, 99, 103]\n",
      "\n",
      "Linear separable classes: Iris-setosa, Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# Calculate errors for each class separately\n",
    "class_names = label_encoder.classes_\n",
    "class_results = {}\n",
    "\n",
    "# Loop through each class (one-vs-rest strategy)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    # Create a binary classification for the current class (vs rest)\n",
    "    y_train_binary = (y_train_encoded == i).astype(int)\n",
    "    y_test_binary = (y_test_encoded == i).astype(int)\n",
    "    \n",
    "    # Train SVM for this class (one-vs-rest)\n",
    "    svm_model_binary = svm.SVC(kernel='linear', C=1e5)\n",
    "    svm_model_binary.fit(X_train, y_train_binary)\n",
    "    \n",
    "    # Predictions for this class\n",
    "    y_train_pred_binary = svm_model_binary.predict(X_train)\n",
    "    y_test_pred_binary = svm_model_binary.predict(X_test)\n",
    "    \n",
    "    # Calculate training and testing errors for this class\n",
    "    train_error_class = 1 - accuracy_score(y_train_binary, y_train_pred_binary)\n",
    "    test_error_class = 1 - accuracy_score(y_test_binary, y_test_pred_binary)\n",
    "    \n",
    "    # Get weight vector, bias, and support vectors for this class\n",
    "    w_class = svm_model_binary.coef_[0]\n",
    "    b_class = svm_model_binary.intercept_[0]\n",
    "    support_vectors_class = svm_model_binary.support_\n",
    "    \n",
    "    # Store results for the class\n",
    "    class_results[class_name] = {\n",
    "        'training_error': train_error_class,\n",
    "        'testing_error': test_error_class,\n",
    "        'w': w_class,\n",
    "        'b': b_class,\n",
    "        'support_vector_indices': support_vectors_class\n",
    "    }\n",
    "\n",
    "# Check which classes are linearly separable (testing error == 0)\n",
    "linearly_separable_classes = [class_name for class_name, results in class_results.items() if results['testing_error'] == 0]\n",
    "\n",
    "#lass_results, linearly_separable_classes\n",
    "# Function to format and output results according to the required format\n",
    "def print_svm_results(train_error, test_error, class_results, linearly_separable_classes):\n",
    "    print(f\"Q2.2.2 Calculation using Standard SVM Model:\")\n",
    "    print(f\"total training error: {train_error:.3f}, total testing error: {test_error:.3f}\\n\")\n",
    "    \n",
    "    for class_name, results in class_results.items():\n",
    "        print(f\"class {class_name.lower()}:\")\n",
    "        print(f\"training error: {results['training_error']:.3f}, testing error: {results['testing_error']:.3f},\")\n",
    "        print(f\"w: [{', '.join(f'{w_value:.6f}' for w_value in results['w'])}], b: {results['b']:.4f},\")\n",
    "        print(f\"support vector indices: [{', '.join(map(str, results['support_vector_indices']))}]\\n\")\n",
    "    \n",
    "    print(f\"Linear separable classes: {', '.join(linearly_separable_classes)}\")\n",
    "\n",
    "# Print results in the required format\n",
    "print_svm_results(train_error, test_error, class_results, linearly_separable_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "C=0.25,\n",
      "total training error: 0.371, total testing error: 0.356\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "w: [-0.167742, 0.418548, -0.787097, -0.318548], b: 1.9413,\n",
      "support vector indices: [42, 64, 23, 24]\n",
      "slack variable: [0.207904, 0.000001, 0.030322, 0.000000]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.333, testing error: 0.333,\n",
      "w: [0.172386, -0.781574, -0.035647, -0.171586], b: 0.7823,\n",
      "support vector indices: [1, 2, 3, 8, 9, 12, 13, 25, 29, 30, 34, 71, 72, 73, 75, 76, 77, 78, 81, 82, 83, 84, 86, 88, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "slack variable: [0.198065, 0.010837, 0.064627, 0.190029, 0.133501, 0.197985, 0.122486, 0.208174, 0.000143, 0.095539, 0.133501, 0.164094, 0.090889, 0.093308, 0.152129, 0.220967, 0.240741, 0.467762, 0.260397, 0.053432, 0.289577, 0.000144, 0.053192, 0.436986, 0.661558, 0.041431, 0.339277, 0.274575, 0.000000, 0.182744, 0.005626, 0.137228, 0.197485, 0.326108, 0.120069, 0.240764, 0.361937, 1.919778, 2.033239, 1.883147, 1.432829, 1.706935, 1.806962, 2.152923, 1.537989, 1.733537, 1.810768, 1.215250, 1.952423, 1.217002, 1.840453, 1.870276, 1.882642, 2.014832, 1.645831, 1.286142, 1.534023, 2.181601, 1.720184, 1.517634, 1.727978, 1.757320, 1.821723, 1.645190, 1.877349, 1.867721, 1.563524, 1.469539, 1.448816, 1.673019, 1.749953, 2.049310]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.048, testing error: 0.022,\n",
      "w: [-0.203610, -0.354710, 1.492195, 1.090648], b: -6.9793,\n",
      "support vector indices: [35, 37, 39, 40, 41, 48, 51, 53, 55, 57, 58, 61, 62, 63, 68, 69, 71, 76, 80, 81, 83, 85, 86, 89, 91, 93, 96, 97, 99, 103, 104]\n",
      "slack variable: [0.000619, 0.463955, 0.204153, 0.000000, 0.325804, 0.290281, 0.167240, 0.328843, 0.810068, 0.798947, 0.107622, 0.332444, 0.907497, 0.121267, 1.196592, 0.207962, 0.435492, 1.294748, 0.646309, 0.259219, 0.384344, 0.000315, 0.196619, 0.884338, 0.619615, 0.944801, 1.109130, 1.010492, 0.109617, 1.009027, 0.260330]\n",
      "\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "C=0.5,\n",
      "total training error: 0.295, total testing error: 0.311\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "w: [-0.012579, 0.506943, -0.810381, -0.358696], b: 0.9484,\n",
      "support vector indices: [42, 64, 23, 24]\n",
      "slack variable: [0.070458, 0.000000, 0.000000, 0.000000]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.286, testing error: 0.311,\n",
      "w: [0.344904, -1.563096, -0.071261, -0.343281], b: 2.5637,\n",
      "support vector indices: [1, 2, 3, 8, 9, 12, 13, 25, 29, 30, 34, 71, 72, 73, 75, 76, 77, 78, 81, 82, 83, 84, 86, 88, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "slack variable: [0.396039, 0.021565, 0.129132, 0.379896, 0.266931, 0.395876, 0.244803, 0.416277, 0.000186, 0.190986, 0.266931, 0.328138, 0.181919, 0.186668, 0.304488, 0.441756, 0.481689, 0.935616, 0.520828, 0.106952, 0.579065, 0.000188, 0.106465, 0.874183, 1.323105, 0.082771, 0.678800, 0.549170, 0.000000, 0.365496, 0.011260, 0.274484, 0.395176, 0.652414, 0.240156, 0.481592, 0.723928, 1.839380, 2.066399, 1.766142, 0.865739, 1.413796, 1.613937, 2.305779, 1.076124, 1.466959, 1.621651, 0.430648, 1.904853, 0.433993, 1.680865, 1.740602, 1.765164, 2.029703, 1.291648, 0.572283, 1.068086, 2.363214, 1.440345, 1.035226, 1.455900, 1.514562, 1.643345, 1.290249, 1.754595, 1.735432, 1.127072, 0.939141, 0.897686, 1.346052, 1.499897, 2.098684]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.019, testing error: 0.022,\n",
      "w: [-0.472293, -0.574701, 1.887610, 1.389421], b: -7.0883,\n",
      "support vector indices: [37, 39, 41, 48, 51, 53, 55, 57, 61, 62, 68, 69, 71, 76, 80, 81, 83, 86, 89, 91, 93, 96, 97, 99, 103]\n",
      "slack variable: [0.204710, 0.000000, 0.134566, 0.181020, 0.121117, 0.297502, 0.847598, 0.832906, 0.096647, 0.823284, 1.376118, 0.215575, 0.112597, 0.983044, 0.591610, 0.018451, 0.000247, 0.000000, 0.664234, 0.314189, 0.865208, 1.064209, 0.943159, 0.041716, 0.961982]\n",
      "\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "C=0.75,\n",
      "total training error: 0.276, total testing error: 0.267\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "w: [0.009733, 0.537779, -0.827351, -0.382043], b: 0.7735,\n",
      "support vector indices: [42, 23, 24]\n",
      "slack variable: [0.000000, 0.000000, 0.000000]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.267, testing error: 0.267,\n",
      "w: [0.466248, -2.000104, -0.113734, -0.415741], b: 3.4739,\n",
      "support vector indices: [1, 2, 3, 8, 9, 12, 13, 25, 29, 30, 34, 71, 72, 73, 75, 76, 77, 78, 81, 82, 83, 84, 86, 88, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "slack variable: [0.515805, 0.033908, 0.164547, 0.482691, 0.345995, 0.510754, 0.311751, 0.539683, 0.000000, 0.246423, 0.345995, 0.407883, 0.239839, 0.225694, 0.393350, 0.539670, 0.612328, 1.189488, 0.664886, 0.145459, 0.731079, 0.000003, 0.130306, 1.122748, 1.678855, 0.095796, 0.870196, 0.705329, 0.000000, 0.470067, 0.012048, 0.347607, 0.505708, 0.840136, 0.306033, 0.607294, 0.898772, 1.779306, 2.077883, 1.690242, 0.557397, 1.242590, 1.521067, 2.388839, 0.832820, 1.312827, 1.527514, 0.008901, 1.876866, 0.000000, 1.598899, 1.665341, 1.685050, 2.050860, 1.104215, 0.171028, 0.816271, 2.469849, 1.277700, 0.769928, 1.315740, 1.371956, 1.531665, 1.083888, 1.678003, 1.664351, 0.882589, 0.651512, 0.598565, 1.164617, 1.374145, 2.144110]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.019, testing error: 0.022,\n",
      "w: [-0.519427, -0.768232, 1.942324, 1.593216], b: -6.8702,\n",
      "support vector indices: [37, 41, 48, 51, 53, 55, 57, 61, 62, 68, 69, 71, 76, 80, 86, 89, 91, 93, 96, 97, 99, 103]\n",
      "slack variable: [0.071442, 0.000308, 0.092843, 0.046591, 0.349520, 0.797778, 0.844037, 0.000300, 0.765026, 1.394005, 0.150476, 0.024144, 0.887051, 0.612538, 0.000605, 0.575433, 0.226225, 0.831644, 1.050757, 0.958228, 0.100150, 0.997968]\n",
      "\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "C=1.0,\n",
      "total training error: 0.276, total testing error: 0.267\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "w: [0.009733, 0.537779, -0.827351, -0.382043], b: 0.7735,\n",
      "support vector indices: [42, 23, 24]\n",
      "slack variable: [0.000000, 0.000000, 0.000000]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.267, testing error: 0.267,\n",
      "w: [0.559441, -2.063736, -0.184894, -0.365990], b: 3.3436,\n",
      "support vector indices: [1, 2, 3, 8, 9, 12, 13, 25, 29, 30, 34, 71, 72, 73, 75, 76, 77, 78, 81, 82, 83, 86, 88, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "slack variable: [0.561633, 0.055487, 0.168938, 0.488286, 0.373369, 0.542288, 0.318036, 0.580598, 0.000019, 0.262337, 0.373369, 0.377962, 0.265001, 0.189087, 0.415296, 0.471346, 0.619102, 1.201379, 0.676647, 0.171126, 0.716655, 0.113091, 1.168068, 1.686603, 0.060080, 0.902097, 0.731260, 0.000000, 0.487431, 0.000251, 0.341608, 0.522429, 0.881800, 0.305009, 0.597704, 0.842716, 1.725625, 2.060910, 1.648773, 0.541399, 1.197961, 1.553826, 2.396805, 0.844215, 1.275192, 1.552836, 0.000000, 1.872415, 1.610001, 1.649739, 1.631616, 2.095715, 1.107754, 0.109062, 0.806515, 2.505895, 1.237603, 0.746196, 1.330429, 1.331612, 1.481186, 1.030508, 1.645975, 1.665565, 0.846388, 0.637596, 0.582508, 1.143973, 1.400353, 2.207603]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.019, testing error: 0.022,\n",
      "w: [-0.485304, -0.756339, 1.996898, 1.680002], b: -7.5195,\n",
      "support vector indices: [37, 41, 48, 51, 53, 55, 57, 61, 62, 68, 69, 71, 76, 80, 89, 91, 93, 96, 97, 99, 103]\n",
      "slack variable: [0.092055, 0.000590, 0.064186, 0.000000, 0.313714, 0.806035, 0.837041, 0.000000, 0.800439, 1.398744, 0.096885, 0.000195, 0.946293, 0.550077, 0.590777, 0.210147, 0.810227, 1.037020, 0.940068, 0.012694, 0.990482]\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Slack variable function\n",
    "def compute_slack(X, y, w, b):\n",
    "    f_x = np.dot(X, w) + b  # Compute f(X) = w.X + b\n",
    "    slack = np.maximum(0, 1 - y * f_x)  # Compute slack variable as max(0, 1 - y * f(X))\n",
    "    return slack\n",
    "\n",
    "# Prepare the class results for each value of C\n",
    "def train_svm_with_slack(C, X_train, y_train_encoded, X_test, y_test_encoded, class_names):\n",
    "    class_results = {}\n",
    "    models = {}\n",
    "\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        # Create a binary classification for the current class (one-vs-rest)\n",
    "        y_train_binary = (y_train_encoded == i).astype(int) * 2 - 1  # Convert to +1 and -1\n",
    "        y_test_binary = (y_test_encoded == i).astype(int) * 2 - 1  # Convert to +1 and -1\n",
    "\n",
    "        # Train SVM with linear kernel and slack (with given C)\n",
    "        svm_model = svm.SVC(kernel='linear', C=C)\n",
    "        svm_model.fit(X_train, y_train_binary)\n",
    "        models[class_name] = svm_model\n",
    "\n",
    "        # Predictions and errors\n",
    "        y_train_pred = svm_model.predict(X_train)\n",
    "        y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "        train_error_class = 1 - accuracy_score(y_train_binary, y_train_pred)\n",
    "        test_error_class = 1 - accuracy_score(y_test_binary, y_test_pred)\n",
    "\n",
    "        # Get weight vector, bias, support vectors, and slack variables\n",
    "        w_class = svm_model.coef_[0]\n",
    "        b_class = svm_model.intercept_[0]\n",
    "        support_vectors_class = svm_model.support_\n",
    "\n",
    "        # Compute slack variables for support vectors\n",
    "        slack = compute_slack(X_train.iloc[support_vectors_class], y_train_binary[support_vectors_class], w_class, b_class)\n",
    "\n",
    "        # Store results for the class\n",
    "        class_results[class_name] = {\n",
    "            'training_error': train_error_class,\n",
    "            'testing_error': test_error_class,\n",
    "            'w': w_class,\n",
    "            'b': b_class,\n",
    "            'support_vector_indices': support_vectors_class,\n",
    "            'slack_variable': slack\n",
    "        }\n",
    "\n",
    "    return class_results, models\n",
    "\n",
    "# Function to format and print results for each C\n",
    "def print_svm_slack_results(C, train_error, test_error, class_results):\n",
    "    print(f\"-------------------------------------------\")\n",
    "    print(f\"C={C},\")\n",
    "    print(f\"total training error: {train_error:.3f}, total testing error: {test_error:.3f}\\n\")\n",
    "    \n",
    "    for class_name, results in class_results.items():\n",
    "        print(f\"class {class_name.lower()}:\")\n",
    "        print(f\"training error: {results['training_error']:.3f}, testing error: {results['testing_error']:.3f},\")\n",
    "        print(f\"w: [{', '.join(f'{w_value:.6f}' for w_value in results['w'])}], b: {results['b']:.4f},\")\n",
    "        print(f\"support vector indices: [{', '.join(map(str, results['support_vector_indices']))}]\")\n",
    "        print(f\"slack variable: [{', '.join(f'{slack_value:.6f}' for slack_value in results['slack_variable'])}]\\n\")\n",
    "    print(f\"-------------------------------------------\")\n",
    "\n",
    "# Main loop for C values\n",
    "C_values = [0.25 * t for t in range(1, 5)]\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "for C in C_values:\n",
    "    # Train and test the SVM model for each C\n",
    "    class_results, models = train_svm_with_slack(C, X_train, y_train_encoded, X_test, y_test_encoded, class_names)\n",
    "\n",
    "    # Collect the predictions for each class\n",
    "    y_train_pred = np.zeros((len(X_train), len(class_names)))\n",
    "    y_test_pred = np.zeros((len(X_test), len(class_names)))\n",
    "\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        y_train_pred[:, i] = models[class_name].predict(X_train)\n",
    "        y_test_pred[:, i] = models[class_name].predict(X_test)\n",
    "\n",
    "    # Take the class with the highest decision function (argmax) for final prediction\n",
    "    y_train_final_pred = np.argmax(y_train_pred, axis=1)\n",
    "    y_test_final_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "    # Calculate total training and testing errors\n",
    "    total_train_error = 1 - accuracy_score(y_train_encoded, y_train_final_pred)\n",
    "    total_test_error = 1 - accuracy_score(y_test_encoded, y_test_final_pred)\n",
    "\n",
    "    # Print results for the current C\n",
    "    print_svm_slack_results(C, total_train_error, total_test_error, class_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "(2nd-order Polynomial),\n",
      "total training error: 0.006, total testing error: 0.007\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "support vector indices: [42, 23, 24]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.010, testing error: 0.022,\n",
      "support vector indices: [31, 76, 89, 97, 101, 103, 104, 55, 58, 62, 68]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.010, testing error: 0.000,\n",
      "support vector indices: [32, 55, 57, 58, 68, 76, 89, 96, 97, 103]\n",
      "\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "(3rd-order Polynomial),\n",
      "total training error: 0.003, total testing error: 0.015\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "support vector indices: [42, 23, 24]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.010, testing error: 0.044,\n",
      "support vector indices: [23, 76, 89, 93, 103, 104, 55, 57, 58, 61, 68]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "support vector indices: [55, 57, 58, 68, 76, 89, 93, 96, 103]\n",
      "\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "(RBF with σ=1),\n",
      "total training error: 0.000, total testing error: 0.044\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "support vector indices: [35, 42, 45, 47, 49, 50, 53, 55, 69, 70, 76, 78, 79, 84, 87, 88, 89, 99, 101, 104, 13, 14, 15, 18, 20, 22, 23, 24, 25]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.000, testing error: 0.067,\n",
      "support vector indices: [13, 14, 15, 18, 20, 22, 23, 24, 25, 71, 76, 79, 88, 89, 90, 96, 97, 100, 101, 103, 38, 41, 42, 45, 55, 57, 62, 68]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.000, testing error: 0.067,\n",
      "support vector indices: [13, 14, 15, 20, 22, 23, 24, 25, 38, 41, 42, 45, 55, 57, 62, 68, 71, 76, 79, 88, 89, 90, 96, 97, 99, 100, 101, 103]\n",
      "\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "(Sigmoidal with σ=1),\n",
      "total training error: 0.333, total testing error: 0.333\n",
      "\n",
      "class iris-setosa:\n",
      "training error: 0.333, testing error: 0.333,\n",
      "support vector indices: [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "\n",
      "class iris-versicolor:\n",
      "training error: 0.333, testing error: 0.333,\n",
      "support vector indices: [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "\n",
      "class iris-virginica:\n",
      "training error: 0.333, testing error: 0.333,\n",
      "support vector indices: [35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104]\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to train and test SVM with different kernel types\n",
    "def train_svm_with_kernel(kernel_type, X_train, y_train_encoded, X_test, y_test_encoded, class_names, degree=None, gamma=None):\n",
    "    class_results = {}\n",
    "\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        # Create a binary classification for the current class (one-vs-rest)\n",
    "        y_train_binary = (y_train_encoded == i).astype(int) * 2 - 1  # Convert to +1 and -1\n",
    "        y_test_binary = (y_test_encoded == i).astype(int) * 2 - 1  # Convert to +1 and -1\n",
    "\n",
    "        # Define the SVM model with the appropriate kernel and hyperparameters\n",
    "        if kernel_type == 'poly':\n",
    "            svm_model = svm.SVC(kernel=kernel_type, degree=degree, C=1e5)  # Polynomial kernel\n",
    "        elif kernel_type == 'rbf':\n",
    "            svm_model = svm.SVC(kernel=kernel_type, gamma=gamma, C=1e5)  # RBF kernel\n",
    "        elif kernel_type == 'sigmoid':\n",
    "            svm_model = svm.SVC(kernel=kernel_type, gamma=gamma, C=1e5)  # Sigmoidal kernel\n",
    "        else:\n",
    "            raise ValueError(\"Unknown kernel type\")\n",
    "\n",
    "        # Train the SVM\n",
    "        svm_model.fit(X_train, y_train_binary)\n",
    "\n",
    "        # Predictions and errors\n",
    "        y_train_pred = svm_model.predict(X_train)\n",
    "        y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "        train_error_class = 1 - accuracy_score(y_train_binary, y_train_pred)\n",
    "        test_error_class = 1 - accuracy_score(y_test_binary, y_test_pred)\n",
    "\n",
    "        # Get support vectors\n",
    "        support_vectors_class = svm_model.support_\n",
    "\n",
    "        # Store results for the class\n",
    "        class_results[class_name] = {\n",
    "            'training_error': train_error_class,\n",
    "            'testing_error': test_error_class,\n",
    "            'support_vector_indices': support_vectors_class\n",
    "        }\n",
    "\n",
    "    return class_results\n",
    "\n",
    "# Function to format and print results for each kernel\n",
    "def print_svm_kernel_results(kernel_name, class_results):\n",
    "    print(f\"-------------------------------------------\")\n",
    "    print(f\"({kernel_name}),\")\n",
    "    \n",
    "    total_train_error = np.mean([results['training_error'] for results in class_results.values()])\n",
    "    total_test_error = np.mean([results['testing_error'] for results in class_results.values()])\n",
    "    \n",
    "    print(f\"total training error: {total_train_error:.3f}, total testing error: {total_test_error:.3f}\\n\")\n",
    "    \n",
    "    for class_name, results in class_results.items():\n",
    "        print(f\"class {class_name.lower()}:\")\n",
    "        print(f\"training error: {results['training_error']:.3f}, testing error: {results['testing_error']:.3f},\")\n",
    "        print(f\"support vector indices: [{', '.join(map(str, results['support_vector_indices']))}]\\n\")\n",
    "    print(f\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "# Main experiment for different kernel functions\n",
    "kernels = {\n",
    "    '2nd-order Polynomial': {'kernel': 'poly', 'degree': 2},\n",
    "    '3rd-order Polynomial': {'kernel': 'poly', 'degree': 3},\n",
    "    'RBF with σ=1': {'kernel': 'rbf', 'gamma': 1},\n",
    "    'Sigmoidal with σ=1': {'kernel': 'sigmoid', 'gamma': 1}\n",
    "}\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "for kernel_name, params in kernels.items():\n",
    "    # Train and test SVM with the specific kernel\n",
    "    class_results = train_svm_with_kernel(\n",
    "        kernel_type=params['kernel'],\n",
    "        X_train=X_train,\n",
    "        y_train_encoded=y_train_encoded,\n",
    "        X_test=X_test,\n",
    "        y_test_encoded=y_test_encoded,\n",
    "        class_names=class_names,\n",
    "        degree=params.get('degree'),\n",
    "        gamma=params.get('gamma')\n",
    "    )\n",
    "\n",
    "    # Print the results for the current kernel\n",
    "    print_svm_kernel_results(kernel_name, class_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
