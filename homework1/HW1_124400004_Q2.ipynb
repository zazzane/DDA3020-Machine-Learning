{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. (SVM, 25 points)\n",
    "\n",
    "### Task Description\n",
    "You are asked to write a program that constructs support vector machine models with different kernel functions and slack variables.\n",
    "\n",
    "### Datasets\n",
    "You are provided with the iris dataset. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. There are four features:\n",
    "1. Sepal length in cm;\n",
    "2. Sepal width in cm;\n",
    "3. Petal length in cm;\n",
    "4. Petal width in cm.\n",
    "\n",
    "You need to use these features to classify each iris plant as one of the three possible types.\n",
    "\n",
    "### What you should do\n",
    "You should use the SVM function from the Python sklearn package, which provides various forms of SVM functions. For multiclass SVM, you should use the one vs rest strategy. You are recommended to use `sklearn.svm.SVC()` function. You can use numpy for vector manipulation. For the technical report, you should report the results required as mentioned below (e.g., training error, testing error, and so on).\n",
    "\n",
    "1. **(2 points)** Split training set and test set. Split the data into a training set and a test set. The training set should contain 70% of the samples, while the test set should include 30%. The number of samples from each category in both the training and test sets should reflect this 70-30 split; for each category, the first 70% of the samples will form the training set, and the remaining 30% will form the test set. Ensure that the split maintains the original order of the data. You should report instance ids in the split training set and test set. The output format is as follows:\n",
    "\n",
    "   **Q2.2.1 Split training set and test set:**\n",
    "   Training set: xx  \n",
    "   Test set: xx  \n",
    "   You should fill up xx in the template. You should write ids for each set in the same line with comma separated, e.g. Training set: [1, 4, 19].\n",
    "\n",
    "2. **(10 points)** Calculation using Standard SVM Model (Linear Kernel). Employ the standard SVM model with a linear kernel. Train your SVM on the split training dataset and validate it on the testing dataset. Calculate the classification error for both the training and testing datasets, output the weight vector w, the bias b, and the indices of support vectors (start with 0). Note that the scikit-learn package does not offer a function with hard margin, so we will simulate this using C = 1e5. You should first print out the total training error and testing error, where the error is:\n",
    "\n",
    "   $\n",
    "   \\text{error} = \\frac{\\text{wrong predictions}}{\\text{number of data}}\n",
    "   $\n",
    "\n",
    "   Then, print out the results for each class separately (note that you should calculate errors for each class separately in this part). You should also mention in your report which classes are linear separable with SVM without slack. The output format is as follows:\n",
    "\n",
    "   **Q2.2.2 Calculation using Standard SVM Model:**\n",
    "   ```{python}\n",
    "   total training error: xx,  \n",
    "   total testing error: xx,  \n",
    "   class setosa:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   class versicolor:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   class virginica:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   Linear separable classes: xx\n",
    "   ```\n",
    "\n",
    "3. **(6 points)** Calculation using SVM with Slack Variables (Linear Kernel). For each C = 0.25 × t, where t = 1, 2, . . . , 4, train your SVM on the training dataset, and subsequently validate it on the testing dataset. Calculate the classification error for both the training and testing datasets, the weight vector w, the bias b, and the indices of support vectors, and the slack variable ζ of support vectors (you may compute it as max(0, 1 − y · f(X)). The output format is as follows:\n",
    "\n",
    "   **Q2.2.3 Calculation using SVM with Slack Variables (C = 0.25 × t, where t = 1, . . . , 4):**\n",
    "   ```{python}\n",
    "   -------------------------------------------  \n",
    "   C=0.25,  \n",
    "   total training error: xx,  \n",
    "   total testing error: xx,  \n",
    "   class setosa:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   slack variable: xx,  \n",
    "   class versicolor:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   slack variable: xx,  \n",
    "   class virginica:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   slack variable: xx,  \n",
    "   -------------------------------------------  \n",
    "   C=0.5,  \n",
    "   <... results for (C=0.5) ...>  \n",
    "   -------------------------------------------  \n",
    "   C=0.75,  \n",
    "   <... results for (C=0.75) ...>  \n",
    "   -------------------------------------------  \n",
    "   C=1,  \n",
    "   <... results for (C=1) ...>\n",
    "   ```\n",
    "\n",
    "4. **(7 points)** Calculation using SVM with Kernel Functions. Conduct experiments with different kernel functions for SVM without slack variable. Calculate the classification error for both the training and testing datasets, and the indices of support vectors for each kernel type:\n",
    "\n",
    "   (a) 2nd-order Polynomial Kernel  \n",
    "   (b) 3rd-order Polynomial Kernel  \n",
    "   (c) Radial Basis Function Kernel with σ = 1  \n",
    "   (d) Sigmoidal Kernel with σ = 1  \n",
    "\n",
    "   The output format is as follows:\n",
    "\n",
    "   **Q2.2.4 Calculation using SVM with Kernel Functions:**\n",
    "   ```{python}\n",
    "   -------------------------------------------  \n",
    "   (a) 2nd-order Polynomial Kernel,  \n",
    "   total training error: xx,  \n",
    "   total testing error: xx,  \n",
    "   class setosa:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   class versicolor:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   class virginica:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   -------------------------------------------  \n",
    "   (b) 3rd-order Polynomial Kernel,  \n",
    "   <... results for (b) ...>  \n",
    "   -------------------------------------------  \n",
    "   (c) Radial Basis Function Kernel with σ = 1,  \n",
    "   <... results for (c) ...>  \n",
    "   -------------------------------------------  \n",
    "   (d) Sigmoidal Kernel with σ = 1,  \n",
    "   <... results for (d) ...>\n",
    "   ```\n",
    "\n",
    "### Submission\n",
    "Submit your executable code in a “HW1 yourID Q2.ipynb” Jupyter notebook (”.py” file is also acceptable). Indicate the corresponding question number in the comment for each cell, and ensure that your code can logically produce the required results for each question in the required format. Please note that you need to write clear comments and use appropriate function/variable names. Excessively unreadable code may result in point deductions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(3020)\n",
    "\n",
    "# Define Constants\n",
    "RANDOM_SEED = 3020\n",
    "C_MARGIN = 1e5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instance_id  sepal length  sepal width  petal length  petal width  \\\n",
       "0            1           5.1          3.5           1.4          0.2   \n",
       "1            2           4.9          3.0           1.4          0.2   \n",
       "2            3           4.7          3.2           1.3          0.2   \n",
       "3            4           4.6          3.1           1.5          0.2   \n",
       "4            5           5.0          3.6           1.4          0.2   \n",
       "\n",
       "         class  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_excel('Classification iris.xlsx')\n",
    "\n",
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train-Test Split\n",
    "- while maintaining order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 22, 25, 26, 27, 28, 29, 30, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 52, 54, 55, 57, 58, 59, 60, 62, 63, 67, 68, 69, 70, 71, 72, 73, 76, 78, 80, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 110, 112, 113, 117, 118, 119, 120, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 136, 137, 138, 140, 141, 143, 144, 146, 147, 149, 150]\n",
      "Length of training set: 105\n",
      "\n",
      "Test set: [2, 3, 9, 17, 19, 20, 21, 23, 24, 31, 32, 34, 37, 45, 50, 51, 53, 56, 61, 64, 65, 66, 74, 75, 77, 79, 81, 90, 91, 99, 104, 109, 111, 114, 115, 116, 121, 124, 125, 134, 135, 139, 142, 145, 148]\n",
      "Length of test set: 45\n"
     ]
    }
   ],
   "source": [
    "# Predictor and Predicted variables\n",
    "X = iris.iloc[:, :-1]  # Features \n",
    "y = iris.iloc[:, -1]   # Target variable \n",
    "\n",
    "# 70-30 Train Test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Reorder the training and test sets based on the instance_id column\n",
    "X_train = X_train.sort_values(by='instance_id').reset_index(drop=True)\n",
    "X_test = X_test.sort_values(by='instance_id').reset_index(drop=True)\n",
    "y_train = y_train.sort_values(ascending=True).reset_index(drop=True)\n",
    "y_test = y_test.sort_values(ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Check the instance ids\n",
    "train_ids = X_train['instance_id'].tolist()  # Instance ids for training set\n",
    "test_ids = X_test['instance_id'].tolist()  # Instance ids for testing set\n",
    "\n",
    "print(f\"Training set: {train_ids}\")\n",
    "print(f\"Length of training set: {len(train_ids)}\")\n",
    "print()\n",
    "print(f\"Test set: {test_ids}\")\n",
    "print(f\"Length of test set: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the instance_id column for training and test sets\n",
    "X_train = X_train.drop(columns='instance_id')\n",
    "X_test = X_test.drop(columns='instance_id')\n",
    "\n",
    "# Label encode the target variable in y_train and y_test\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standard SVM Calculation\n",
    "- Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.2 Calculation using Standard SVM Model:\n",
      "Total training error: 0.0000, total testing error: 0.0444\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.08757428  0.44848304 -0.85088498 -0.44006999], b: 1.600566373049051\n",
      "  Support vector indices: [39 15 28]\n",
      "\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.2571, Testing error: 0.2667\n",
      "  w: [-0.99913856 -3.1328945   1.73950159 -3.13977114], b: 11.166458055426018\n",
      "  Support vector indices: [  1   6  10  15  16  22  24  28  71  75  76  78  80  82  83  84  85  87\n",
      "  90  91  95  96  99 100 101 104  35  37  38  39  40  41  42  45  48  51\n",
      "  52  53  54  55  56  57  58  59  61  62  63  64  66  68  69]\n",
      "\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0000, Testing error: 0.0444\n",
      "  w: [ -1.16007155 -15.28442522  11.40002276  45.05463381], b: -82.99849854088012\n",
      "  Support vector indices: [56 75 83 90]\n",
      "\n",
      "\n",
      "Linear separable classes: ['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "# Train svm\n",
    "svm_2 = svm.SVC(kernel='linear', C=C_MARGIN)\n",
    "svm_2.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = svm_2.predict(X_train)\n",
    "y_test_pred = svm_2.predict(X_test)\n",
    "\n",
    "# Total classification errors\n",
    "total_training_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "total_testing_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print total errors\n",
    "print(f\"Q2.2.2 Calculation using Standard SVM Model:\")\n",
    "print(f\"Total training error: {total_training_error:.4f}, total testing error: {total_testing_error:.4f}\\n\")\n",
    "\n",
    "# Get unique class labels\n",
    "class_labels = le.classes_\n",
    "\n",
    "# Initialize list of linearly separable classes\n",
    "lin_sep_classes = []\n",
    "\n",
    "# Results for each class\n",
    "for i, label in enumerate(class_labels):\n",
    "\n",
    "    # map binary y_train and y_test based on current class vs rest\n",
    "    y_train_mapped = (y_train == i).astype(int)\n",
    "    y_test_mapped = (y_test == i).astype(int)\n",
    "\n",
    "    # Train a binary SVM model for the current class (for-loop local)\n",
    "    svm2_binary = svm.SVC(kernel='linear', C=C_MARGIN)\n",
    "    svm2_binary.fit(X_train, y_train_mapped)\n",
    "\n",
    "    # Predictions for the current class\n",
    "    train_class_pred = svm2_binary.predict(X_train)\n",
    "    test_class_pred = svm2_binary.predict(X_test)\n",
    "\n",
    "    # Calculate training and testing errors for the current class\n",
    "    train_class_error = 1 - accuracy_score(y_train_mapped, train_class_pred)\n",
    "    test_class_error = 1 - accuracy_score(y_test_mapped, test_class_pred)\n",
    "\n",
    "    # Check if the current class is linearly separable\n",
    "    if test_class_error == 0:\n",
    "        lin_sep_classes.append(label)\n",
    "\n",
    "    # Print results for the current class\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  Training error: {train_class_error:.4f}, Testing error: {test_class_error:.4f}\")\n",
    "    print(f\"  w: {svm2_binary.coef_[0]}, b: {svm2_binary.intercept_[0]}\")\n",
    "    print(f\"  Support vector indices: {svm2_binary.support_}\\n\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f\"Linear separable classes: {lin_sep_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SVM calculation with slack variables \n",
    "- linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slack variable function\n",
    "def compute_slack(X, y, w, b):\n",
    "    f_x = np.dot(X, w) + b  # Compute f(X) = w.X + b\n",
    "    slack = np.maximum(0, 1 - y * f_x)  # Compute slack variable as max(0, 1 - y * f(X))\n",
    "    return slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 0.25):\n",
      "Total training error: 0.0286, total testing error: 0.0222\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.08005903  0.34791736 -0.80803542 -0.38898819], b: 1.7271981074005207\n",
      "  Support vector indices: [39 64 15 16 28]\n",
      "  Slack variable ζ:\n",
      "  [1.14405493e-01 7.16078542e-02 8.72311025e-02 0.00000000e+00\n",
      " 6.63229678e-08]\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.3429, Testing error: 0.3111\n",
      "  w: [-0.29652586 -0.92272353  0.25916813 -0.24939231], b: 2.9813980553423742\n",
      "  Support vector indices: [  1   6   9  10  16  20  22  24  25  28  29  31  70  71  72  73  74  75\n",
      "  76  78  79  80  82  83  84  85  86  87  88  89  90  91  93  96  99 101\n",
      " 102 104  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69]\n",
      "  Slack variable ζ:\n",
      "  [9.58099040e-02 3.17913772e-02 1.27799503e-01 1.98311994e-01\n",
      " 9.53887258e-02 0.00000000e+00 3.17913772e-02 3.17913772e-02\n",
      " 1.95553803e-01 7.86868455e-01 1.10090979e-02 7.79210416e-02\n",
      " 0.00000000e+00 6.18106615e-01 1.13261981e-01 2.40321453e-01\n",
      " 1.46416740e-01 9.63902179e-01 3.24714104e-01 4.92024725e-01\n",
      " 9.85524879e-02 2.62327938e-01 5.13725540e-01 1.09400332e+00\n",
      " 5.08366578e-01 3.52164902e-01 0.00000000e+00 3.54412712e-01\n",
      " 2.25437405e-01 4.27624349e-01 1.82388736e-01 3.10561015e-01\n",
      " 4.02685118e-01 1.99708171e-01 6.18106615e-01 5.76174618e-04\n",
      " 6.28471579e-01 3.36576202e-01 2.07691462e+00 1.05929577e+00\n",
      " 1.71156098e+00 2.11263999e+00 1.08025260e+00 1.78360746e+00\n",
      " 1.39028347e+00 1.82185742e+00 1.04046866e+00 1.65514922e+00\n",
      " 1.41660843e+00 1.09488592e+00 1.24953141e+00 1.92571894e+00\n",
      " 1.69857305e+00 1.29768831e+00 1.95265266e+00 1.90162207e+00\n",
      " 1.45018437e+00 1.15450087e+00 1.51832052e+00 1.36638086e+00\n",
      " 1.59584405e+00 2.16778821e+00 2.02176640e+00 1.19284921e+00\n",
      " 1.70893801e+00 1.75255611e+00 1.40013136e+00 1.01763284e+00\n",
      " 1.40620414e+00 1.68773456e+00 1.62040143e+00 1.74274755e+00\n",
      " 1.55404589e+00]\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0286, Testing error: 0.0222\n",
      "  w: [-0.20999813 -0.40119896  1.51745415  1.15132542], b: -6.9279255322176825\n",
      "  Support vector indices: [ 35  37  38  44  46  48  50  52  56  57  58  59  60  62  71  75  78  80\n",
      "  83  84  87  88  90  96  97  99 101 102 104]\n",
      "  Slack variable ζ:\n",
      "  [0.00000000e+00 2.91006792e-01 3.99284896e-01 2.48019900e-01\n",
      " 4.42980189e-01 9.05414541e-01 9.08602351e-01 1.00601412e+00\n",
      " 1.30998537e+00 2.90019525e-01 1.18673608e-01 2.80392895e-01\n",
      " 0.00000000e+00 1.79633710e-01 3.02617380e-01 1.17411685e+00\n",
      " 1.25125425e-01 7.81266363e-02 7.56293109e-01 4.89095939e-01\n",
      " 9.97105314e-01 9.04599877e-01 1.54162660e-04 9.72467193e-02\n",
      " 8.59357303e-03 3.02617380e-01 0.00000000e+00 4.79122067e-01\n",
      " 5.59109421e-01]\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 0.5):\n",
      "Total training error: 0.0095, total testing error: 0.0000\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.09064252  0.43699535 -0.82820392 -0.42711552], b: 1.6080746216144002\n",
      "  Support vector indices: [39 64 15 28]\n",
      "  Slack variable ζ:\n",
      "  [0.05252663 0.         0.00023585 0.        ]\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.2667, Testing error: 0.2444\n",
      "  w: [-0.59353897 -1.84475159  0.519061   -0.50001632], b: 6.962308796885159\n",
      "  Support vector indices: [  1   6   9  10  16  20  22  24  25  28  29  31  70  71  72  73  74  75\n",
      "  76  78  79  80  82  83  84  85  86  87  88  89  90  91  93  96  99 101\n",
      " 102 104  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69]\n",
      "  Slack variable ζ:\n",
      "  [1.91887812e-01 6.38277514e-02 2.55750708e-01 3.96801897e-01\n",
      " 1.90853481e-01 0.00000000e+00 6.38277514e-02 6.38277514e-02\n",
      " 3.91258567e-01 1.57322915e+00 2.23082488e-02 1.55747445e-01\n",
      " 0.00000000e+00 1.23613353e+00 2.26352917e-01 4.80568571e-01\n",
      " 2.92926127e-01 1.92783559e+00 6.49749575e-01 9.83822342e-01\n",
      " 1.96790211e-01 5.24856798e-01 1.02718790e+00 2.18790196e+00\n",
      " 1.01655233e+00 7.04430279e-01 0.00000000e+00 7.08526112e-01\n",
      " 4.50835791e-01 8.55062219e-01 3.65101078e-01 6.21057006e-01\n",
      " 8.05060587e-01 3.99735537e-01 1.23613353e+00 4.22547066e-04\n",
      " 1.25640826e+00 6.73355785e-01 2.15379572e+00 1.18861449e-01\n",
      " 1.42334288e+00 2.22510642e+00 1.60551026e-01 1.56716868e+00\n",
      " 7.80608125e-01 1.64379422e+00 8.11508827e-02 1.31001423e+00\n",
      " 8.32912784e-01 1.90336337e-01 4.99068501e-01 1.85131283e+00\n",
      " 1.39736063e+00 5.95491314e-01 1.90545767e+00 1.80337986e+00\n",
      " 9.00520325e-01 3.09050012e-01 1.03672825e+00 7.32569372e-01\n",
      " 1.19130643e+00 2.33533208e+00 2.04357006e+00 3.86068230e-01\n",
      " 1.41763536e+00 1.50487598e+00 8.00346987e-01 3.54297645e-02\n",
      " 8.12303784e-01 1.37508153e+00 1.24060800e+00 1.48547139e+00\n",
      " 1.10803894e+00]\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0095, Testing error: 0.0000\n",
      "  w: [-0.47842617 -0.73060146  1.79897066  1.39397694], b: -6.076031617746529\n",
      "  Support vector indices: [ 37  38  44  46  48  50  52  56  57  59  62  71  75  83  84  87  88  90\n",
      "  96  97  99 102 104]\n",
      "  Slack variable ζ:\n",
      "  [1.34744660e-01 1.84423927e-01 2.39310856e-01 5.36736319e-01\n",
      " 9.07546995e-01 9.89301531e-01 8.91322789e-01 1.48590092e+00\n",
      " 3.34996090e-01 0.00000000e+00 4.05971435e-02 2.20766684e-04\n",
      " 7.81694708e-01 4.68093115e-01 1.97992117e-01 9.43740274e-01\n",
      " 8.62120882e-01 4.81114591e-02 0.00000000e+00 2.43549723e-04\n",
      " 2.20766684e-04 2.73210627e-01 4.06641515e-01]\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 0.75):\n",
      "Total training error: 0.0095, total testing error: 0.0222\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.08757428  0.44848304 -0.85088498 -0.44006999], b: 1.600566373049051\n",
      "  Support vector indices: [39 15 28]\n",
      "  Slack variable ζ:\n",
      "  [0.         0.         0.00017836]\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.2667, Testing error: 0.2667\n",
      "  w: [-0.66491966 -1.91408278  0.62765747 -0.68013498], b: 7.370522498738445\n",
      "  Support vector indices: [  1   6   9  10  16  22  24  25  28  29  31  71  72  73  74  75  76  78\n",
      "  79  80  82  83  84  85  86  87  88  89  90  91  93  96  99 102 104  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  65  66  67  68  69]\n",
      "  Slack variable ζ:\n",
      "  [0.18369467 0.05223227 0.24736676 0.39152935 0.17190083 0.05223227\n",
      " 0.05223227 0.38255538 1.58790786 0.         0.11133977 1.25476162\n",
      " 0.18224022 0.45041277 0.28914062 1.99543838 0.69576805 0.98134132\n",
      " 0.13065312 0.53416952 1.04055201 2.28810733 1.00279228 0.73624445\n",
      " 0.         0.67710174 0.4235429  0.84220329 0.39304999 0.62713937\n",
      " 0.77418979 0.4092532  1.25476162 1.2423526  0.68205832 2.20577205\n",
      " 0.0624716  1.44386516 2.27317037 0.09024782 1.56573841 0.75940806\n",
      " 1.67879291 0.         1.29101977 0.76077437 0.15870534 0.43851887\n",
      " 1.88905548 1.41846478 0.54835915 1.95069168 1.84462965 0.87946861\n",
      " 0.23813662 1.02233286 0.67418181 1.15803584 2.39063424 2.08830818\n",
      " 0.34334434 1.40605576 1.49270035 0.76815883 0.76906518 1.34176848\n",
      " 1.2183737  1.48806779 1.08973117]\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0095, Testing error: 0.0222\n",
      "  w: [-0.47993535 -0.82062349  1.91535002  1.40786102], b: -6.444012709712783\n",
      "  Support vector indices: [ 37  38  44  46  48  50  52  56  57  75  83  84  87  88  90  97  99 102\n",
      " 104]\n",
      "  Slack variable ζ:\n",
      "  [6.10633402e-02 7.90597706e-02 1.37345459e-01 5.05883038e-01\n",
      " 8.26203467e-01 9.77842462e-01 8.48663783e-01 1.48155448e+00\n",
      " 2.33332529e-01 8.34815845e-01 4.40454883e-01 2.28459325e-01\n",
      " 9.89527743e-01 9.14123904e-01 0.00000000e+00 1.01219714e-04\n",
      " 1.00145618e-04 2.67478126e-01 4.35066830e-01]\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 1.0):\n",
      "Total training error: 0.0190, total testing error: 0.0222\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.08757428  0.44848304 -0.85088498 -0.44006999], b: 1.600566373049051\n",
      "  Support vector indices: [39 15 28]\n",
      "  Slack variable ζ:\n",
      "  [0.         0.         0.00017836]\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.2571, Testing error: 0.2667\n",
      "  w: [-0.85020736 -1.93586122  0.78235794 -0.85925556], b: 8.090107653809966\n",
      "  Support vector indices: [  1   6   9  10  16  22  24  25  28  29  31  71  72  73  74  75  76  78\n",
      "  79  80  82  83  84  85  87  88  89  90  91  93  96  99 102 104  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  65  66  67  68  69]\n",
      "  Slack variable ζ:\n",
      "  [0.17966979 0.01053314 0.2109042  0.4013005  0.11140876 0.01053314\n",
      " 0.01053314 0.3868258  1.57098236 0.         0.03905309 1.28951955\n",
      " 0.05752685 0.40348992 0.18007372 2.14431478 0.65179134 0.93586672\n",
      " 0.         0.51248476 0.93225374 2.35287512 1.02357776 0.64638658\n",
      " 0.60706866 0.38315295 0.80513687 0.3238981  0.51795959 0.71921131\n",
      " 0.40391938 1.28951955 1.17335232 0.70966601 2.31424801 0.02611414\n",
      " 1.54668847 2.35226737 0.         1.65344421 0.70955777 1.73667947\n",
      " 0.         1.24690988 0.71950838 0.20834532 0.4046918  1.91221362\n",
      " 1.50416917 0.56118125 2.08942748 1.96281012 0.91031628 0.19663097\n",
      " 1.04783108 0.62274525 1.0768684  2.44726287 2.21925251 0.39333686\n",
      " 1.38800194 1.50785221 0.77600916 0.72900778 1.30886132 1.20120076\n",
      " 1.54806865 1.08585043]\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0190, Testing error: 0.0222\n",
      "  w: [-0.47621069 -0.88197452  1.96671932  1.48916104], b: -6.71548102224447\n",
      "  Support vector indices: [ 37  38  44  46  48  50  52  56  57  75  83  84  87  88  90  96 102 104]\n",
      "  Slack variable ζ:\n",
      "  [2.71245956e-04 1.14159714e-04 5.57940327e-02 4.75647235e-01\n",
      " 7.73300029e-01 9.50121536e-01 8.13154139e-01 1.45884981e+00\n",
      " 1.51036171e-01 8.72039013e-01 4.45750968e-01 2.36542814e-01\n",
      " 1.01677337e+00 9.48875273e-01 4.91857360e-04 0.00000000e+00\n",
      " 2.57542115e-01 4.60289271e-01]\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM with slack variables for different C values\n",
    "C_values = [0.25 * t for t in range(1, 5)]  # C = 0.25, 0.5, 0.75, 1.0\n",
    "\n",
    "for C in C_values:\n",
    "    # Train SVM model\n",
    "    svm3 = svm.SVC(kernel='linear', C=C)\n",
    "    svm3.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_train_pred = svm3.predict(X_train)\n",
    "    y_test_pred = svm3.predict(X_test)\n",
    "\n",
    "    # Total classification errors\n",
    "    total_training_error = 1 - accuracy_score(y_train_pred, y_train)\n",
    "    total_testing_error = 1 - accuracy_score(y_test_pred, y_test)\n",
    "    \n",
    "    # Results for each class\n",
    "    print(f\"Q2.2.3 Calculation using SVM with Slack Variables (C = {C}):\")\n",
    "    print(f\"Total training error: {total_training_error:.4f}, total testing error: {total_testing_error:.4f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "    for i, label in enumerate(class_labels):\n",
    "\n",
    "        # map binary y_train and y_test based on current class vs rest\n",
    "        y_train_mapped = (y_train == i).astype(int)* 2 - 1\n",
    "        y_test_mapped = (y_test == i).astype(int)* 2 - 1\n",
    "\n",
    "        # Train a binary SVM model for the current class (for-loop local)\n",
    "        svm3_binary = svm.SVC(kernel='linear', C=C)\n",
    "        svm3_binary.fit(X_train, y_train_mapped)\n",
    "\n",
    "        # Predictions for the current class\n",
    "        train_class_pred = svm3_binary.predict(X_train)\n",
    "        test_class_pred = svm3_binary.predict(X_test)\n",
    "\n",
    "        # Calculate training and testing errors for the current class\n",
    "        train_class_error = 1 - accuracy_score(y_train_mapped, train_class_pred)\n",
    "        test_class_error = 1 - accuracy_score(y_test_mapped, test_class_pred)\n",
    "\n",
    "        # Calculate slack variable ζ for support vectors\n",
    "        slack_variables = compute_slack(X_train.iloc[svm3_binary.support_], y_train_mapped[svm3_binary.support_], svm3_binary.coef_[0], svm3_binary.intercept_[0])\n",
    "\n",
    "        # Print results for the current class\n",
    "        print(f\"Class {label}:\")\n",
    "        print(f\"  Training error: {train_class_error:.4f}, Testing error: {test_class_error:.4f}\")\n",
    "        print(f\"  w: {svm3_binary.coef_[0]}, b: {svm3_binary.intercept_[0]}\")\n",
    "        print(f\"  Support vector indices: {svm3_binary.support_}\")\n",
    "        print(f\"  Slack variable ζ:\")\n",
    "        print(f\"  {slack_variables}\")\n",
    "        print()\n",
    "\n",
    "    print(\"---------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculation of SVM using Kernal Functions\n",
    "\n",
    "(a) 2nd-order Polynomial Kernel  \n",
    "(b) 3rd-order Polynomial Kernel  \n",
    "(c) Radial Basis Function Kernel with σ = 1  \n",
    "(d) Sigmoidal Kernel with σ = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_with_kernel(kernel_type, X_train, y_train, X_test, y_test, class_labels, degree=None, gamma=None):\n",
    "    class_results = {}\n",
    "\n",
    "    for i, class_name in enumerate(class_labels):\n",
    "        # binary classification for the current class (one-vs-rest)\n",
    "        y_train_binary = (y_train == i).astype(int) * 2 - 1 \n",
    "        y_test_binary = (y_test == i).astype(int) * 2 - 1  \n",
    "\n",
    "        # define the SVM model with the kernel and hyperparameters\n",
    "        if kernel_type == 'poly':\n",
    "            svm_model = svm.SVC(kernel=kernel_type, degree=degree, C=C_MARGIN)  # Polynomial \n",
    "        elif kernel_type == 'rbf':\n",
    "            svm_model = svm.SVC(kernel=kernel_type, gamma=gamma, C=C_MARGIN)  # RBF \n",
    "        elif kernel_type == 'sigmoid':\n",
    "            svm_model = svm.SVC(kernel=kernel_type, gamma=gamma, C=C_MARGIN)  # Sigmoidal \n",
    "        else:\n",
    "            raise ValueError(\"Incorrect kernel type provided\")\n",
    "\n",
    "        # Train SVM\n",
    "        svm_model.fit(X_train, y_train_binary)\n",
    "\n",
    "        # Predictions\n",
    "        y_train_pred = svm_model.predict(X_train)\n",
    "        y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "        # Calculate errors\n",
    "        train_error_class = 1 - accuracy_score(y_train_binary, y_train_pred)\n",
    "        test_error_class = 1 - accuracy_score(y_test_binary, y_test_pred)\n",
    "\n",
    "\n",
    "        # Store results for the class\n",
    "        class_results[class_name] = {\n",
    "            'training_error': train_error_class,\n",
    "            'testing_error': test_error_class,\n",
    "            'support_vector_indices': svm_model.support_\n",
    "        }\n",
    "\n",
    "    return class_results\n",
    "\n",
    "\n",
    "# Function to format and print results for each kernel\n",
    "def output_kernel_results(kernel_name, class_results):\n",
    "    print(f\"-------------------------------------------\")\n",
    "    print(f\"({kernel_name}),\")\n",
    "    \n",
    "    total_training_error = np.mean([results['training_error'] for results in class_results.values()])\n",
    "    total_testing_error = np.mean([results['testing_error'] for results in class_results.values()])\n",
    "    \n",
    "    print(f\"Total training error: {total_training_error:.3f}, total testing error: {total_testing_error:.3f}\\n\")\n",
    "    \n",
    "    for class_name, results in class_results.items():\n",
    "        print(f\"Class {class_name}:\")\n",
    "        print(f\"training error: {results['training_error']:.3f}, testing error: {results['testing_error']:.3f},\")\n",
    "        print(f\"support vector indices: [{', '.join(map(str, results['support_vector_indices']))}]\\n\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "((a) 2nd-order Polynomial),\n",
      "Total training error: 0.000, total testing error: 0.030\n",
      "\n",
      "Class Iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "support vector indices: [39, 15, 28]\n",
      "\n",
      "Class Iris-versicolor:\n",
      "training error: 0.000, testing error: 0.044,\n",
      "support vector indices: [15, 28, 75, 83, 88, 90, 48, 52, 56]\n",
      "\n",
      "Class Iris-virginica:\n",
      "training error: 0.000, testing error: 0.044,\n",
      "support vector indices: [48, 56, 75, 83, 90]\n",
      "\n",
      "-------------------------------------------\n",
      "((b) 3rd-order Polynomial),\n",
      "Total training error: 0.000, total testing error: 0.030\n",
      "\n",
      "Class Iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "support vector indices: [39, 15, 28]\n",
      "\n",
      "Class Iris-versicolor:\n",
      "training error: 0.000, testing error: 0.044,\n",
      "support vector indices: [28, 75, 83, 88, 90, 48, 52, 56]\n",
      "\n",
      "Class Iris-virginica:\n",
      "training error: 0.000, testing error: 0.044,\n",
      "support vector indices: [46, 48, 56, 75, 83, 88, 90]\n",
      "\n",
      "-------------------------------------------\n",
      "((c) RBF with σ=1),\n",
      "Total training error: 0.000, total testing error: 0.030\n",
      "\n",
      "Class Iris-setosa:\n",
      "training error: 0.000, testing error: 0.000,\n",
      "support vector indices: [39, 43, 51, 53, 58, 70, 75, 77, 81, 82, 83, 84, 90, 92, 101, 103, 10, 11, 12, 15, 21, 28, 30]\n",
      "\n",
      "Class Iris-versicolor:\n",
      "training error: 0.000, testing error: 0.044,\n",
      "support vector indices: [10, 11, 12, 15, 28, 30, 75, 81, 82, 83, 88, 90, 104, 39, 46, 48, 52, 56]\n",
      "\n",
      "Class Iris-virginica:\n",
      "training error: 0.000, testing error: 0.044,\n",
      "support vector indices: [10, 11, 12, 15, 21, 28, 30, 39, 46, 48, 52, 56, 75, 81, 82, 83, 88, 90, 104]\n",
      "\n",
      "-------------------------------------------\n",
      "((d) Sigmoidal with σ=1),\n",
      "Total training error: 0.333, total testing error: 0.333\n",
      "\n",
      "Class Iris-setosa:\n",
      "training error: 0.333, testing error: 0.333,\n",
      "support vector indices: [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "\n",
      "Class Iris-versicolor:\n",
      "training error: 0.333, testing error: 0.333,\n",
      "support vector indices: [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "\n",
      "Class Iris-virginica:\n",
      "training error: 0.333, testing error: 0.333,\n",
      "support vector indices: [35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run each kernel and print the results\n",
    "class_labels = le.classes_\n",
    "\n",
    "kernels = {\n",
    "    '(a) 2nd-order Polynomial': {\n",
    "        'kernel': 'poly', \n",
    "        'degree': 2\n",
    "        },\n",
    "    '(b) 3rd-order Polynomial': {\n",
    "        'kernel': 'poly', \n",
    "        'degree': 3\n",
    "        },\n",
    "    '(c) RBF with σ=1': {\n",
    "        'kernel': 'rbf', \n",
    "        'gamma': 1\n",
    "        },\n",
    "    '(d) Sigmoidal with σ=1': {\n",
    "        'kernel': 'sigmoid', \n",
    "        'gamma': 1\n",
    "        }\n",
    "}\n",
    "\n",
    "for kernel_name, params in kernels.items():\n",
    "    \n",
    "    class_results = train_svm_with_kernel(\n",
    "        kernel_type=params['kernel'],\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        class_labels=class_labels,\n",
    "        degree=params.get('degree'),\n",
    "        gamma=params.get('gamma')\n",
    "    )\n",
    "\n",
    "    # Print the results for the current kernel\n",
    "    output_kernel_results(kernel_name, class_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
