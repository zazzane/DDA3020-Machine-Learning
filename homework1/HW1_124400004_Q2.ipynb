{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. (SVM, 25 points)\n",
    "\n",
    "### Task Description\n",
    "You are asked to write a program that constructs support vector machine models with different kernel functions and slack variables.\n",
    "\n",
    "### Datasets\n",
    "You are provided with the iris dataset. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. There are four features:\n",
    "1. Sepal length in cm;\n",
    "2. Sepal width in cm;\n",
    "3. Petal length in cm;\n",
    "4. Petal width in cm.\n",
    "\n",
    "You need to use these features to classify each iris plant as one of the three possible types.\n",
    "\n",
    "### What you should do\n",
    "You should use the SVM function from the Python sklearn package, which provides various forms of SVM functions. For multiclass SVM, you should use the one vs rest strategy. You are recommended to use `sklearn.svm.SVC()` function. You can use numpy for vector manipulation. For the technical report, you should report the results required as mentioned below (e.g., training error, testing error, and so on).\n",
    "\n",
    "1. **(2 points)** Split training set and test set. Split the data into a training set and a test set. The training set should contain 70% of the samples, while the test set should include 30%. The number of samples from each category in both the training and test sets should reflect this 70-30 split; for each category, the first 70% of the samples will form the training set, and the remaining 30% will form the test set. Ensure that the split maintains the original order of the data. You should report instance ids in the split training set and test set. The output format is as follows:\n",
    "\n",
    "   **Q2.2.1 Split training set and test set:**\n",
    "   Training set: xx  \n",
    "   Test set: xx  \n",
    "   You should fill up xx in the template. You should write ids for each set in the same line with comma separated, e.g. Training set: [1, 4, 19].\n",
    "\n",
    "2. **(10 points)** Calculation using Standard SVM Model (Linear Kernel). Employ the standard SVM model with a linear kernel. Train your SVM on the split training dataset and validate it on the testing dataset. Calculate the classification error for both the training and testing datasets, output the weight vector w, the bias b, and the indices of support vectors (start with 0). Note that the scikit-learn package does not offer a function with hard margin, so we will simulate this using C = 1e5. You should first print out the total training error and testing error, where the error is:\n",
    "\n",
    "   $\n",
    "   \\text{error} = \\frac{\\text{wrong predictions}}{\\text{number of data}}\n",
    "   $\n",
    "\n",
    "   Then, print out the results for each class separately (note that you should calculate errors for each class separately in this part). You should also mention in your report which classes are linear separable with SVM without slack. The output format is as follows:\n",
    "\n",
    "   **Q2.2.2 Calculation using Standard SVM Model:**\n",
    "   ```{python}\n",
    "   total training error: xx,  \n",
    "   total testing error: xx,  \n",
    "   class setosa:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   class versicolor:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   class virginica:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   Linear separable classes: xx\n",
    "   ```\n",
    "\n",
    "3. **(6 points)** Calculation using SVM with Slack Variables (Linear Kernel). For each C = 0.25 × t, where t = 1, 2, . . . , 4, train your SVM on the training dataset, and subsequently validate it on the testing dataset. Calculate the classification error for both the training and testing datasets, the weight vector w, the bias b, and the indices of support vectors, and the slack variable ζ of support vectors (you may compute it as max(0, 1 − y · f(X)). The output format is as follows:\n",
    "\n",
    "   **Q2.2.3 Calculation using SVM with Slack Variables (C = 0.25 × t, where t = 1, . . . , 4):**\n",
    "   ```{python}\n",
    "   -------------------------------------------  \n",
    "   C=0.25,  \n",
    "   total training error: xx,  \n",
    "   total testing error: xx,  \n",
    "   class setosa:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   slack variable: xx,  \n",
    "   class versicolor:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   slack variable: xx,  \n",
    "   class virginica:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   slack variable: xx,  \n",
    "   -------------------------------------------  \n",
    "   C=0.5,  \n",
    "   <... results for (C=0.5) ...>  \n",
    "   -------------------------------------------  \n",
    "   C=0.75,  \n",
    "   <... results for (C=0.75) ...>  \n",
    "   -------------------------------------------  \n",
    "   C=1,  \n",
    "   <... results for (C=1) ...>\n",
    "   ```\n",
    "\n",
    "4. **(7 points)** Calculation using SVM with Kernel Functions. Conduct experiments with different kernel functions for SVM without slack variable. Calculate the classification error for both the training and testing datasets, and the indices of support vectors for each kernel type:\n",
    "\n",
    "   (a) 2nd-order Polynomial Kernel  \n",
    "   (b) 3rd-order Polynomial Kernel  \n",
    "   (c) Radial Basis Function Kernel with σ = 1  \n",
    "   (d) Sigmoidal Kernel with σ = 1  \n",
    "\n",
    "   The output format is as follows:\n",
    "\n",
    "   **Q2.2.4 Calculation using SVM with Kernel Functions:**\n",
    "   ```{python}\n",
    "   -------------------------------------------  \n",
    "   (a) 2nd-order Polynomial Kernel,  \n",
    "   total training error: xx,  \n",
    "   total testing error: xx,  \n",
    "   class setosa:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   class versicolor:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   class virginica:  \n",
    "   training error: xx,  \n",
    "   testing error: xx,  \n",
    "   w: xx,  \n",
    "   b: xx,  \n",
    "   support vector indices: xx,  \n",
    "   -------------------------------------------  \n",
    "   (b) 3rd-order Polynomial Kernel,  \n",
    "   <... results for (b) ...>  \n",
    "   -------------------------------------------  \n",
    "   (c) Radial Basis Function Kernel with σ = 1,  \n",
    "   <... results for (c) ...>  \n",
    "   -------------------------------------------  \n",
    "   (d) Sigmoidal Kernel with σ = 1,  \n",
    "   <... results for (d) ...>\n",
    "   ```\n",
    "\n",
    "### Submission\n",
    "Submit your executable code in a “HW1 yourID Q2.ipynb” Jupyter notebook (”.py” file is also acceptable). Indicate the corresponding question number in the comment for each cell, and ensure that your code can logically produce the required results for each question in the required format. Please note that you need to write clear comments and use appropriate function/variable names. Excessively unreadable code may result in point deductions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(3020)\n",
    "\n",
    "# Define Constants\n",
    "RANDOM_SEED = 3020\n",
    "C_MARGIN = 1e5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instance_id  sepal length  sepal width  petal length  petal width  \\\n",
       "0            1           5.1          3.5           1.4          0.2   \n",
       "1            2           4.9          3.0           1.4          0.2   \n",
       "2            3           4.7          3.2           1.3          0.2   \n",
       "3            4           4.6          3.1           1.5          0.2   \n",
       "4            5           5.0          3.6           1.4          0.2   \n",
       "\n",
       "         class  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_excel('Classification iris.xlsx')\n",
    "\n",
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train-Test Split\n",
    "- while maintaining order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predictor and Predicted variables\n",
    "# X = iris.iloc[:, :-1]  # Features \n",
    "# y = iris.iloc[:, -1]   # Target variable \n",
    "\n",
    "# # 70-30 Train Test split with stratification\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# # Check the instance ids\n",
    "# train_ids = X_train['instance_id'].tolist()  # Instance ids for training set\n",
    "# test_ids = X_test['instance_id'].tolist()  # Instance ids for testing set\n",
    "\n",
    "# print(f\"Training set: {train_ids}\")\n",
    "# print(f\"Length of training set: {len(train_ids)}\")\n",
    "# print()\n",
    "# print(f\"Test set: {test_ids}\")\n",
    "# print(f\"Length of test set: {len(test_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 22, 25, 26, 27, 28, 29, 30, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 52, 54, 55, 57, 58, 59, 60, 62, 63, 67, 68, 69, 70, 71, 72, 73, 76, 78, 80, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 110, 112, 113, 117, 118, 119, 120, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 136, 137, 138, 140, 141, 143, 144, 146, 147, 149, 150]\n",
      "Length of training set: 105\n",
      "\n",
      "Test set: [2, 3, 9, 17, 19, 20, 21, 23, 24, 31, 32, 34, 37, 45, 50, 51, 53, 56, 61, 64, 65, 66, 74, 75, 77, 79, 81, 90, 91, 99, 104, 109, 111, 114, 115, 116, 121, 124, 125, 134, 135, 139, 142, 145, 148]\n",
      "Length of test set: 45\n"
     ]
    }
   ],
   "source": [
    "# Predictor and Predicted variables\n",
    "X = iris.iloc[:, :-1]  # Features \n",
    "y = iris.iloc[:, -1]   # Target variable \n",
    "\n",
    "# 70-30 Train Test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# Reorder the training and test sets based on the instance_id column\n",
    "X_train = X_train.sort_values(by='instance_id').reset_index(drop=True)\n",
    "X_test = X_test.sort_values(by='instance_id').reset_index(drop=True)\n",
    "y_train = y_train.sort_values(ascending=True).reset_index(drop=True)\n",
    "y_test = y_test.sort_values(ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Check the instance ids\n",
    "train_ids = X_train['instance_id'].tolist()  # Instance ids for training set\n",
    "test_ids = X_test['instance_id'].tolist()  # Instance ids for testing set\n",
    "\n",
    "print(f\"Training set: {train_ids}\")\n",
    "print(f\"Length of training set: {len(train_ids)}\")\n",
    "print()\n",
    "print(f\"Test set: {test_ids}\")\n",
    "print(f\"Length of test set: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standard SVM Calculation\n",
    "- Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.2 Calculation using Standard SVM Model:\n",
      "Total training error: 0.0000, total testing error: 0.0000\n",
      "\n",
      "Class setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34]\n",
      "\n",
      "\n",
      "Class versicolor:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58\n",
      " 59 60 61 62 63 64 65 66 67 68 69]\n",
      "\n",
      "\n",
      "Class virginica:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [ 70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104]\n",
      "\n",
      "\n",
      "Linear separable classes: ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# Train svm\n",
    "svm_2 = svm.SVC(kernel='linear', C=C_MARGIN)\n",
    "svm_2.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = svm_2.predict(X_train)\n",
    "y_test_pred = svm_2.predict(X_test)\n",
    "\n",
    "# Total classification errors\n",
    "total_training_error = np.mean(y_train_pred != y_train)\n",
    "total_testing_error = np.mean(y_test_pred != y_test)\n",
    "\n",
    "# Print total errors\n",
    "print(f\"Q2.2.2 Calculation using Standard SVM Model:\")\n",
    "print(f\"Total training error: {total_training_error:.4f}, total testing error: {total_testing_error:.4f}\\n\")\n",
    "\n",
    "# Get unique class labels\n",
    "class_labels = np.unique(y_train)\n",
    "\n",
    "# Get Xtrain vectors\n",
    "xtrain_sv = iris.loc[iris['instance_id'].isin(X_train['instance_id'])]\n",
    "\n",
    "# Initialize list of linearly separable classes\n",
    "lin_sep_classes = []\n",
    "\n",
    "# Results for each class\n",
    "for label in class_labels:\n",
    "    # Get indices of the current class\n",
    "    train_class_indices = np.where(y_train == label)[0]\n",
    "    test_class_indices = np.where(y_test == label)[0]\n",
    "\n",
    "    # Predictions for the current class\n",
    "    train_class_pred = y_train_pred[train_class_indices]\n",
    "    test_class_pred = y_test_pred[test_class_indices]\n",
    "\n",
    "    # Calculate training and testing errors for the current class\n",
    "    train_class_error = np.mean(train_class_pred != label)\n",
    "    test_class_error = np.mean(test_class_pred != label)\n",
    "\n",
    "    # Get support vectors for the current class\n",
    "    support_vector_indices = X_train.iloc[svm_2.support_]\n",
    "    support_vectors = xtrain_sv.loc[xtrain_sv['instance_id'].isin(support_vector_indices['instance_id'])]\n",
    "    sv_instance_ids = support_vectors.loc[support_vectors['class'] == label]['instance_id'].tolist()\n",
    "\n",
    "    # Check if the current class is linearly separable\n",
    "    if train_class_error == 0 and test_class_error == 0:\n",
    "        lin_sep_classes.append(label)\n",
    "\n",
    "    # Print results for the current class\n",
    "    print(f\"Class {label[5:]}:\")\n",
    "    print(f\"  Training error: {train_class_error:.4f}, Testing error: {test_class_error:.4f}\")\n",
    "    print(f\"  w: {svm_2.coef_[0]}, b: {svm_2.intercept_[0]}\")\n",
    "    print(f\"  Support vector indices: {train_class_indices}\\n\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f\"Linear separable classes: {lin_sep_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SVM calculation with slack variables \n",
    "- linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 0.25):\n",
      "Total training error: 0.0000, total testing error: 0.0000\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34    23.882875\n",
      "35     0.000000\n",
      "69     0.000000\n",
      "70     0.000000\n",
      "71     0.000000\n",
      "Name: class, dtype: float64\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34     0.000000\n",
      "35    23.882875\n",
      "69    23.882875\n",
      "70     0.000000\n",
      "71     0.000000\n",
      "Name: class, dtype: float64\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34     0.000000\n",
      "35     0.000000\n",
      "69     0.000000\n",
      "70    23.882875\n",
      "71    23.882875\n",
      "Name: class, dtype: float64\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 0.5):\n",
      "Total training error: 0.0000, total testing error: 0.0000\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34    23.882875\n",
      "35     0.000000\n",
      "69     0.000000\n",
      "70     0.000000\n",
      "71     0.000000\n",
      "Name: class, dtype: float64\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34     0.000000\n",
      "35    23.882875\n",
      "69    23.882875\n",
      "70     0.000000\n",
      "71     0.000000\n",
      "Name: class, dtype: float64\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34     0.000000\n",
      "35     0.000000\n",
      "69     0.000000\n",
      "70    23.882875\n",
      "71    23.882875\n",
      "Name: class, dtype: float64\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 0.75):\n",
      "Total training error: 0.0000, total testing error: 0.0000\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34    23.882875\n",
      "35     0.000000\n",
      "69     0.000000\n",
      "70     0.000000\n",
      "71     0.000000\n",
      "Name: class, dtype: float64\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34     0.000000\n",
      "35    23.882875\n",
      "69    23.882875\n",
      "70     0.000000\n",
      "71     0.000000\n",
      "Name: class, dtype: float64\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34     0.000000\n",
      "35     0.000000\n",
      "69     0.000000\n",
      "70    23.882875\n",
      "71    23.882875\n",
      "Name: class, dtype: float64\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 1.0):\n",
      "Total training error: 0.0000, total testing error: 0.0000\n",
      "\n",
      "Class Iris-setosa:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34    23.882875\n",
      "35     0.000000\n",
      "69     0.000000\n",
      "70     0.000000\n",
      "71     0.000000\n",
      "Name: class, dtype: float64\n",
      "\n",
      "Class Iris-versicolor:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34     0.000000\n",
      "35    23.882875\n",
      "69    23.882875\n",
      "70     0.000000\n",
      "71     0.000000\n",
      "Name: class, dtype: float64\n",
      "\n",
      "Class Iris-virginica:\n",
      "  Training error: 0.0000, Testing error: 0.0000\n",
      "  w: [-0.28368952 -0.10401949  0.04728159 -0.28368952 -0.12293212], b: 15.727268361785079\n",
      "  Support vector indices: [34 35 69 70 71]\n",
      "  Slack variable ζ:\n",
      "  34     0.000000\n",
      "35     0.000000\n",
      "69     0.000000\n",
      "70    23.882875\n",
      "71    23.882875\n",
      "Name: class, dtype: float64\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM with slack variables for different C values\n",
    "C_values = [0.25 * t for t in range(1, 5)]  # C = 0.25, 0.5, 0.75, 1.0\n",
    "\n",
    "for C in C_values:\n",
    "    # Train SVM model\n",
    "    svm_model = svm.SVC(kernel='linear', C=C)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_train_pred = svm_model.predict(X_train)\n",
    "    y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "    # Total classification errors\n",
    "    total_training_error = np.mean(y_train_pred != y_train)\n",
    "    total_testing_error = np.mean(y_test_pred != y_test)\n",
    "\n",
    "    # Results for each class\n",
    "    print(f\"Q2.2.3 Calculation using SVM with Slack Variables (C = {C}):\")\n",
    "    print(f\"Total training error: {total_training_error:.4f}, total testing error: {total_testing_error:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # Get unique class labels\n",
    "    class_labels = np.unique(y_train)\n",
    "\n",
    "    for label in class_labels:\n",
    "        # Get indices of the current class\n",
    "        train_class_indices = np.where(y_train == label)[0]\n",
    "        test_class_indices = np.where(y_test == label)[0]\n",
    "\n",
    "        # Predictions for the current class\n",
    "        train_class_pred = y_train_pred[train_class_indices]\n",
    "        test_class_pred = y_test_pred[test_class_indices]\n",
    "\n",
    "        # Calculate training and testing errors for the current class\n",
    "        train_class_error = np.mean(train_class_pred != label)\n",
    "        test_class_error = np.mean(test_class_pred != label)\n",
    "\n",
    "        # Encode the class label\n",
    "        target_label = label\n",
    "        label_mapping = {target_label: 1}\n",
    "        for l in class_labels:\n",
    "            if l != target_label:\n",
    "                label_mapping[l] = -1\n",
    "\n",
    "        # Apply the mapping to y_train\n",
    "        y_train_mapped = y_train.map(label_mapping) \n",
    "\n",
    "        # Calculate slack variable ζ for support vectors\n",
    "        decision_values = np.dot(svm_model.support_, svm_model.coef_[0]) + svm_model.intercept_[0]\n",
    "        slack_variables = np.maximum(0, 1 - y_train_mapped[svm_model.support_] * decision_values)\n",
    "\n",
    "        # empty the mapping dictionary\n",
    "        label_mapping = {}\n",
    "\n",
    "        # Print results for the current class\n",
    "        print(f\"Class {label}:\")\n",
    "        print(f\"  Training error: {train_class_error:.4f}, Testing error: {test_class_error:.4f}\")\n",
    "        print(f\"  w: {svm_model.coef_[0]}, b: {svm_model.intercept_[0]}\")\n",
    "        print(f\"  Support vector indices: {svm_model.support_}\")\n",
    "        print(f\"  Slack variable ζ:\")\n",
    "        print(f\"  {slack_variables}\")\n",
    "        print()\n",
    "\n",
    "    print(\"---------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculation of SVM using Kernal Functions\n",
    "\n",
    "(a) 2nd-order Polynomial Kernel  \n",
    "(b) 3rd-order Polynomial Kernel  \n",
    "(c) Radial Basis Function Kernel with σ = 1  \n",
    "(d) Sigmoidal Kernel with σ = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "(2nd-order Polynomial Kernel)\n",
      "total training error: 0.0000,\n",
      "total testing error: 0.0000,\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [34, 35, 69, 70, 71],\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [34, 35, 69, 70, 71],\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [34, 35, 69, 70, 71],\n",
      "\n",
      "-------------------------------------------\n",
      "(3rd-order Polynomial Kernel)\n",
      "total training error: 0.0000,\n",
      "total testing error: 0.0000,\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [34, 35, 69, 70],\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [34, 35, 69, 70],\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [34, 35, 69, 70],\n",
      "\n",
      "-------------------------------------------\n",
      "(Radial Basis Function Kernel)\n",
      "total training error: 0.0000,\n",
      "total testing error: 0.0444,\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104],\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104],\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104],\n",
      "\n",
      "-------------------------------------------\n",
      "(Sigmoidal Kernel)\n",
      "total training error: 0.6667,\n",
      "total testing error: 0.6667,\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104],\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104],\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.0000, testing error: 0.0000\n",
      "\n",
      "support vector indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104],\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate errors and support vectors based on kernel types\n",
    "def calculate_svm(kernel, degree=3, C=1e5, gamma=0.0):\n",
    "    \n",
    "    if gamma == 1.0:\n",
    "        svm = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    else:\n",
    "        svm = SVC(kernel=kernel, C=C, degree=degree)\n",
    "        \n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = svm.predict(X_train)\n",
    "    y_test_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate errors\n",
    "    train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "    test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Get support vectors\n",
    "    support_vectors_indices = svm.support_\n",
    "    \n",
    "    return train_error, test_error, None, None, support_vectors_indices\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "# (a) 2nd-order Polynomial Kernel\n",
    "results['2nd-order Polynomial Kernel'] = calculate_svm(kernel='poly', degree=2)\n",
    "\n",
    "# (b) 3rd-order Polynomial Kernel\n",
    "results['3rd-order Polynomial Kernel'] = calculate_svm(kernel='poly', degree=3)\n",
    "\n",
    "# (c) Radial Basis Function Kernel with σ = 1\n",
    "results['Radial Basis Function Kernel'] = calculate_svm(kernel='rbf', gamma=1.0)\n",
    "\n",
    "# (d) Sigmoidal Kernel with σ = 1\n",
    "results['Sigmoidal Kernel'] = calculate_svm(kernel='sigmoid', gamma=1.0)\n",
    "\n",
    "# Output results\n",
    "for kernel_type, (train_error, test_error, w, b, support_vectors) in results.items():\n",
    "    print(f\"-------------------------------------------\")\n",
    "    print(f\"({kernel_type})\")\n",
    "    print(f\"total training error: {train_error:.4f},\")\n",
    "    print(f\"total testing error: {test_error:.4f},\")\n",
    "    print()\n",
    "    \n",
    "    # For each class, we will output the errors and support vectors\n",
    "    for class_label in np.unique(y):\n",
    "        class_indices = np.where(y_train == class_label)[0]\n",
    "        class_train_error = np.mean(y_train[class_indices] != y_train_pred[class_indices])\n",
    "        class_test_error = np.mean(y_test[y_test == class_label] != y_test_pred[y_test == class_label])\n",
    "        \n",
    "        print(f\"class {class_label}:\")\n",
    "        print(f\"training error: {class_train_error:.4f}, testing error: {class_test_error:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        if w is not None and b is not None:\n",
    "            print(f\"w: {w}, b: {b},\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"support vector indices: {support_vectors.tolist() if support_vectors is not None else 'N/A'},\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0 == None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
